# 컨테이너화 및 배포 가이드

## 1. 프로젝트 구성

- **Frontend**: React 19.1.0 + Vite + Nginx
- **Backend**: Spring Boot + PostgreSQL
- **AI Module**: Python 3.12 + FastAPI + LangChain
- **Database**: PostgreSQL 15
- **Vector DB**: ChromaDB
- **LLM**: Ollama

## 2. 컨테이너 구조

### 2.1 Frontend Container
```dockerfile
# Node.js 22.16 버전의 Alpine Linux 기반 이미지를 사용하여 빌드 단계를 정의
FROM node:22.16-alpine AS build

# 컨테이너 내부의 작업 디렉토리를 /app으로 설정
WORKDIR /app

# Node.js 바이너리들을 PATH에 추가
ENV PATH=/app/node_modules/.bin:$PATH

# package.json 복사 및 의존성 설치
COPY package.json /app/package.json
RUN npm install

# 소스 코드 복사
COPY . /app

# 빌드 시 환경변수 설정
ARG VITE_API_URL
ENV VITE_API_URL=${VITE_API_URL}

# React 앱 빌드
RUN echo "VITE_API_URL=$VITE_API_URL" > .env && npm run build

# 두 번째 단계: Nginx 웹서버 단계
FROM nginx:latest

# Nginx 기본 설정 파일 제거
RUN rm /etc/nginx/conf.d/default.conf

# 커스텀 Nginx 설정 파일 복사
COPY nginx/nginx.conf /etc/nginx/conf.d

# 빌드된 React 앱을 Nginx 웹 루트로 복사
COPY --from=build /app/dist /usr/share/nginx/html

# 포트 80 노출
EXPOSE 80

# Nginx를 포그라운드 모드로 실행
ENTRYPOINT ["nginx", "-g", "daemon off;"]
```

### 2.2 Backend Container
```dockerfile
# Stage 1: Build
FROM gradle:8.3-jdk17 AS builder
WORKDIR /app
COPY . .
RUN chmod +x ./gradlew && ./gradlew clean bootJar

# Stage 2: Run
FROM openjdk:17
WORKDIR /app
COPY --from=builder /app/build/libs/*.jar app.jar
ENTRYPOINT ["java", "-jar", "app.jar", "--spring.profiles.active=prod"]
```

### 2.3 LLM Service Container
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Poetry 설치
RUN pip install poetry

# pyproject.toml과 poetry.lock 복사
COPY pyproject.toml poetry.lock* ./

# Poetry 설정 (가상환경 생성 비활성화)
RUN poetry config virtualenvs.create false

# 의존성 설치
RUN poetry install --only=main

# 소스 코드 복사
COPY . .

# 포트 8000 노출
EXPOSE 8000

# 엔트리포인트 스크립트 실행 권한 부여
RUN chmod +x /app/entrypoint.sh

# FastAPI 앱 실행
ENTRYPOINT ["/app/entrypoint.sh"]
```

### 2.4 Ollama Container
```dockerfile
# Ollama 컨테이너 설정 (ollama.Dockerfile)
FROM ollama/ollama:latest

# 필요한 환경 변수 설정
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_PORT=11434

# 기본 모델 다운로드 (선택사항)
RUN ollama pull llama2

# 포트 노출
EXPOSE 11434

# Ollama 서버 실행
CMD ["ollama", "serve"]
```

## 3. 엔트리포인트 스크립트

### 3.1 LLM Service 엔트리포인트 (`entrypoint.sh`)
```bash
#!/bin/bash
set -e

# Ollama 서버를 백그라운드에서 실행
echo "Starting Ollama server..."
ollama serve &

# 서버가 준비될 때까지 대기 (Health Check)
echo "Waiting for Ollama server to be ready..."
while ! curl -s -f http://ollama:11434/ > /dev/null; do
    echo "Ollama server not yet available, waiting..."
    sleep 1
done
echo "Ollama server is ready."

# 메인 Python 애플리케이션 실행 (FastAPI/Uvicorn 예시)
# 이 부분이 실제 서비스의 핵심입니다.
echo "Starting the Python LLM service on port 8000..."
exec uvicorn llm-service.main:app --host 0.0.0.0 --port 8000
```

## 4. Docker Compose 구성

### 4.1 통합 Docker Compose
```yaml
version: '3.8'

services:
  # PostgreSQL 데이터베이스
  db:
    image: postgres:15
    container_name: alreadydb
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Ollama LLM 서비스
  ollama:
    build:
      context: ./llm-service
      dockerfile: ollama.Dockerfile
    container_name: ollama_svc
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ChromaDB 벡터 데이터베이스
  chroma:
    image: chromadb/chroma
    container_name: chroma_svc
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5

  # LLM 서비스 (kwonsoonmin/llm-service:0.4 이미지 사용)
  llm-service:
    image: kwonsoonmin/llm-service:0.4
    container_name: llm-svc
    depends_on:
      ollama:
        condition: service_healthy
      chroma:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - SPRING_SERVER_URL=${SPRING_SERVER_URL}
      - VECTOR_DB_HOST=${VECTOR_DB_HOST}
      - VECTOR_DB_PORT=${VECTOR_DB_PORT}
      - LANGSMITH_TRACING=true
      - LANGSMITH_PROJECT=llm-service-already
      - LANGSMITH_ENDPOINT=${LANGSMITH_ENDPOINT}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    entrypoint: ["/app/entrypoint.sh"]

  # Spring Boot 백엔드
  backend:
    image: hyeon31/alreadyserver:0.1
    container_name: already-server
    ports:
      - "8080:8080"
    depends_on:
      db:
        condition: service_healthy
      llm-service:
        condition: service_healthy
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SPRING_DATASOURCE_URL: jdbc:postgresql://db:5432/${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      MAIL_USERNAME: ${MAIL_USERNAME}
      MAIL_PASSWORD: ${MAIL_PASSWORD}
      SPRING_PROFILES_ACTIVE: prod
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # React 프론트엔드
  frontend:
    image: hanmg412/prj3:fclient0.4
    container_name: react-client
    ports:
      - "80:80"
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  shared-network:
    driver: bridge

volumes:
  pgdata:
  ollama_data:
  chroma_data:
```

## 5. 환경 변수 설정

### 5.1 개발 환경 (.env.dev)
```env
# 데이터베이스
POSTGRES_DB=alreadydb_dev
POSTGRES_USER=dev_user
POSTGRES_PASSWORD=dev_password

# 백엔드
JWT_SECRET=your-dev-jwt-secret
MAIL_USERNAME=your-dev-email@gmail.com
MAIL_PASSWORD=your-dev-email-password

# LLM 서비스
OLLAMA_BASE_URL=http://ollama:11434
GOOGLE_API_KEY=your-google-api-key
TAVILY_API_KEY=your-tavily-api-key
SPRING_SERVER_URL=http://backend:8080
VECTOR_DB_HOST=chroma
VECTOR_DB_PORT=8000
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your-langsmith-api-key

# 프론트엔드
VITE_API_URL=http://localhost:8080
```

### 5.2 운영 환경 (.env.prod)
```env
# 데이터베이스
POSTGRES_DB=alreadydb_prod
POSTGRES_USER=prod_user
POSTGRES_PASSWORD=your-secure-password

# 백엔드
JWT_SECRET=your-production-jwt-secret
MAIL_USERNAME=your-production-email@gmail.com
MAIL_PASSWORD=your-production-email-password

# LLM 서비스
OLLAMA_BASE_URL=http://ollama:11434
GOOGLE_API_KEY=your-google-api-key
TAVILY_API_KEY=your-tavily-api-key
SPRING_SERVER_URL=http://backend:8080
VECTOR_DB_HOST=chroma
VECTOR_DB_PORT=8000
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your-langsmith-api-key

# 프론트엔드
VITE_API_URL=https://your-domain.com
```

## 6. 네트워크 및 포트 구성

| 서비스 | 컨테이너 포트 | 호스트 포트 | 설명 |
|--------|---------------|-------------|------|
| Frontend | 80 | 80 | React + Nginx |
| Backend | 8080 | 8080 | Spring Boot API |
| LLM Service | 8000 | 8000 | FastAPI + LangChain |
| ChromaDB | 8000 | 8001 | 벡터 데이터베이스 |
| Ollama | 11434 | 11434 | 로컬 LLM |
| PostgreSQL | 5432 | 5432 | 메인 데이터베이스 |

## 7. 빌드 및 배포 스크립트

### 7.1 개발 환경 배포
```bash
#!/bin/bash
# dev-deploy.sh

echo "개발 환경 배포 시작..."

# 환경 변수 로드
export $(cat .env.dev | xargs)

# 네트워크 생성
docker network create shared-network 2>/dev/null || true

# 컨테이너 실행
docker-compose -f docker-compose.yml --env-file .env.dev up -d

```

### 7.2 운영 환경 배포
```bash
#!/bin/bash
# prod-deploy.sh

echo "운영 환경 배포 시작..."

# 환경 변수 로드
export $(cat .env.prod | xargs)

# 네트워크 생성
docker network create shared-network 2>/dev/null || true

# 기존 컨테이너 중지 및 제거
docker-compose -f docker-compose.yml down

# 이미지 업데이트
docker-compose -f docker-compose.yml pull

# 컨테이너 실행
docker-compose -f docker-compose.yml --env-file .env.prod up -d

```

## 8. 모니터링 및 헬스체크

### 8.2 로그 모니터링
```bash
# 전체 서비스 로그
docker-compose logs -f

# 특정 서비스 로그
docker-compose logs -f frontend
docker-compose logs -f backend
docker-compose logs -f llm-service
docker-compose logs -f ollama
docker-compose logs -f chroma
```

## 9. CI/CD 파이프라인

### 9.1 GitHub Actions (LLM Service)
```yaml
name: Build and Push, and Deploy LLM Service

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

env:
  DOCKER_IMAGE: llm-service
  DOCKER_TAG: 0.4
  PROJECT_DIRECTORY: llm-svc

jobs:
  Docker:
    runs-on: ubuntu-latest

    steps:
      # 소스 코드 체크아웃
      - name: Checkout Code
        uses: actions/checkout@v4

      # Docker Hub 로그인
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      # Docker 이미지 빌드 및 푸시
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./llm-service.Dockerfile
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}

      # EC2 배포
      - name: Deploy to EC2
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd ~
            if [ ! -d "${{ env.PROJECT_DIRECTORY }}" ]; then
              git clone https://github.com/rookies-team1/langchain.git ${{ env.PROJECT_DIRECTORY }}
            fi
            cd ${{ env.PROJECT_DIRECTORY }}
            git pull origin main
                      
            # 환경 변수 설정
            echo "OLLAMA_BASE_URL=${{ secrets.OLLAMA_BASE_URL }}" > .env
            echo "GOOGLE_API_KEY=${{ secrets.GOOGLE_API_KEY }}" >> .env
            echo "TAVILY_API_KEY=${{ secrets.TAVILY_API_KEY }}" >> .env
            echo "VECTOR_DB_PORT=${{ secrets.VECTOR_DB_PORT }}" >> .env
            echo "VECTOR_DB_HOST=${{ secrets.VECTOR_DB_HOST }}" >> .env
            echo "SPRING_SERVER_URL=${{ secrets.SPRING_SERVER_URL }}" >> .env
            echo "LANGSMITH_ENDPOINT=${{ secrets.LANGSMITH_ENDPOINT }}" >> .env
            echo "LANGSMITH_API_KEY=${{ secrets.LANGSMITH_API_KEY }}" >> .env

            # 이미지 업데이트 및 컨테이너 재시작
            docker-compose pull
            docker-compose down
            docker-compose up -d

            # 헬스체크 대기
            echo "서비스 시작 대기 중..."
            sleep 60
            
            # 헬스체크
            if curl -f http://localhost:8000/health; then
              echo "LLM 서비스 배포 성공"
            else
              echo "LLM 서비스 배포 실패"
              exit 1
            fi

      # 빌드 결과 출력
      - name: Image digest
        run: echo "Image pushed successfully to ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}"
```

### 9.2 전체 애플리케이션 배포 파이프라인
```yaml
name: Deploy Full Application

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/frontend:${{ github.sha }}

      - name: Build and push Backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/backend:${{ github.sha }}

      - name: Build and push LLM Service
        uses: docker/build-push-action@v5
        with:
          context: ./llm-service
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/llm-service:${{ github.sha }}

      - name: Deploy to EC2
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd ~/already-app
            git pull origin main
            
            # 환경 변수 업데이트
            echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}" > .env.prod
            echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}" >> .env.prod
            echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}" >> .env.prod
            echo "JWT_SECRET=${{ secrets.JWT_SECRET }}" >> .env.prod
            echo "MAIL_USERNAME=${{ secrets.MAIL_USERNAME }}" >> .env.prod
            echo "MAIL_PASSWORD=${{ secrets.MAIL_PASSWORD }}" >> .env.prod
            echo "OLLAMA_BASE_URL=${{ secrets.OLLAMA_BASE_URL }}" >> .env.prod
            echo "GOOGLE_API_KEY=${{ secrets.GOOGLE_API_KEY }}" >> .env.prod
            echo "TAVILY_API_KEY=${{ secrets.TAVILY_API_KEY }}" >> .env.prod
            echo "SPRING_SERVER_URL=${{ secrets.SPRING_SERVER_URL }}" >> .env.prod
            echo "VECTOR_DB_HOST=${{ secrets.VECTOR_DB_HOST }}" >> .env.prod
            echo "VECTOR_DB_PORT=${{ secrets.VECTOR_DB_PORT }}" >> .env.prod
            echo "LANGSMITH_ENDPOINT=${{ secrets.LANGSMITH_ENDPOINT }}" >> .env.prod
            echo "LANGSMITH_API_KEY=${{ secrets.LANGSMITH_API_KEY }}" >> .env.prod
            echo "VITE_API_URL=${{ secrets.VITE_API_URL }}" >> .env.prod
            
            # 배포 실행
            ./prod-deploy.sh
```

## 10. 클라우드 배포 (AWS)

### 10.1 EC2 인스턴스 설정
```bash
#!/bin/bash
# ec2-setup.sh

# EC2 인스턴스 초기 설정
sudo yum update -y
sudo yum install -y docker git curl

# Docker 서비스 시작
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user

# Docker Compose 설치
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# 프로젝트 클론
git clone https://github.com/your-repo/already-app.git
cd already-app

# 환경 변수 설정
cp .env.prod.example .env.prod
# 실제 환경 변수 값으로 수정 필요

# 첫 배포 실행
./prod-deploy.sh
```

### 10.2 Auto Scaling Group 설정 (선택사항)
```json
{
  "LaunchTemplate": {
    "LaunchTemplateName": "already-app-template",
    "ImageId": "ami-0abcdef1234567890",
    "InstanceType": "t3.medium",
    "KeyName": "your-key-pair",
    "SecurityGroupIds": ["sg-0123456789abcdef0"],
    "UserData": "IyEvYmluL2Jhc2gKc3VkbyB5dW0gdXBkYXRlIC15CnN1ZG8geXVtIGluc3RhbGwgLXkgZG9ja2Vy..."
  }
}
```

## 11. 보안 고려사항

### 11.1 환경 변수 보안
```bash
# AWS Systems Manager Parameter Store 사용 예시
aws ssm put-parameter \
  --name "/already-app/prod/jwt-secret" \
  --value "your-jwt-secret" \
  --type "SecureString"

# 런타임에 환경 변수 가져오기
export JWT_SECRET=$(aws ssm get-parameter \
  --name "/already-app/prod/jwt-secret" \
  --with-decryption \
  --query 'Parameter.Value' \
  --output text)
```

### 11.2 네트워크 보안
```yaml
# 내부 네트워크만 허용하는 서비스
services:
  db:
    networks:
      - internal
    # 외부 포트 노출하지 않음
  
  chroma:
    networks:
      - internal
    # 외부 포트 노출하지 않음

networks:
  internal:
    driver: bridge
    internal: true
  shared-network:
    driver: bridge
```

# 컨테이너화 및 배포 가이드 - 추가 섹션

## 14. 트러블슈팅

### 14.1 서비스별 트러블슈팅 가이드

#### Frontend (React + Nginx) 문제
```bash
# 1. 빌드 시 환경변수 확인
docker build --build-arg VITE_API_URL=http://localhost:8080 -t frontend:latest .

# 2. Nginx 설정 확인
docker exec react-client nginx -t
docker exec react-client cat /etc/nginx/conf.d/default.conf

# 3. 정적 파일 확인
docker exec react-client ls -la /usr/share/nginx/html/

# 4. 네트워크 연결 테스트
docker exec react-client curl -I http://backend:8080/actuator/health
```

#### Backend (Spring Boot) 문제
```bash
# 1. 애플리케이션 로그 확인
docker logs already-server --tail 100 -f

# 2. 데이터베이스 연결 확인
docker exec already-server curl -f http://localhost:8080/actuator/health

# 3. 환경변수 확인
docker exec already-server printenv | grep SPRING

# 4. JAR 파일 확인
docker exec already-server ls -la /app/
```

#### LLM Service 문제
```bash
# 1. Ollama 서비스 상태 확인
docker exec ollama_svc ollama list
docker exec ollama_svc ollama ps

# 2. 모델 다운로드 확인
docker exec ollama_svc ollama pull llama2:7b

# 3. FastAPI 서비스 상태
docker exec llm-svc curl -f http://localhost:8000/health

# 4. 의존성 버전 확인
docker exec llm-svc pip list | grep -E "(fastapi|langchain|ollama)"
```

#### 데이터베이스 문제
```bash
# 1. PostgreSQL 연결 테스트
docker exec alreadydb pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}

# 2. 데이터베이스 쿼리 테스트
docker exec alreadydb psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "SELECT version();"

# 3. 테이블 확인
docker exec alreadydb psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "\dt"
```

### 14.2 일반적인 문제 해결 방법

#### 컨테이너 시작 실패
```bash
# 1. 포트 충돌 확인
sudo netstat -tulpn | grep -E "(80|8080|8000|5432|11434)"

# 2. 기존 컨테이너 정리
docker-compose down --remove-orphans
docker system prune -f

# 3. 볼륨 권한 문제
sudo chown -R $USER:$USER ./data
```

#### 네트워크 연결 문제
```bash
# 1. 네트워크 상태 확인
docker network ls
docker network inspect shared-network

# 2. 컨테이너 간 통신 테스트
docker exec llm-svc ping -c 3 ollama
docker exec backend ping -c 3 db

# 3. DNS 해결 확인
docker exec llm-svc nslookup ollama
```

#### 메모리 부족 문제
```bash
# 1. 시스템 리소스 확인
free -h
df -h

# 2. 컨테이너 리소스 사용량
docker stats --no-stream

# 3. 메모리 제한 설정
docker-compose up -d --scale llm-service=1 --memory=2g
```

## 15. 모니터링 및 로깅

#### 로그 수집 설정
```yaml
# 기존 docker-compose.yml에 로깅 설정 추가
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=backend"
    
  llm-service:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=llm-service"
```

## 16. 보안 강화

### 16.1 컨테이너 보안 설정

#### 보안 강화된 Docker Compose
```yaml
version: '3.8'

services:
  backend:
    image: hyeon31/alreadyserver:0.1
    container_name: already-server
    # 보안 설정
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    user: "1000:1000"
    # 리소스 제한
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    # 환경 설정
    environment:
      SPRING_PROFILES_ACTIVE: prod
    secrets:
      - jwt_secret
      - db_password

secrets:
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  db_password:
    file: ./secrets/db_password.txt
```

#### 네트워크 보안 설정
```yaml
# 내부 전용 네트워크
networks:
  frontend-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
  backend-network:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.21.0.0/24

services:
  frontend:
    networks:
      - frontend-network
  
  backend:
    networks:
      - frontend-network
      - backend-network
  
  db:
    networks:
      - backend-network
```

### 16.2 SSL/TLS 설정

#### Nginx SSL 설정
```nginx
# nginx/nginx.conf
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;

    location / {
        try_files $uri $uri/ /index.html;
    }

    location /api {
        proxy_pass http://backend:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

## 17. 성능 최적화

### 17.1 컨테이너 최적화

#### 멀티스테이지 빌드 최적화
```dockerfile
# LLM Service 최적화된 Dockerfile
FROM python:3.12-slim as builder

# 빌드 의존성 설치
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Poetry 설치 및 의존성 빌드
RUN pip install poetry
COPY pyproject.toml poetry.lock ./
RUN poetry config virtualenvs.create false \
    && poetry install --only=main --no-dev

# 운영 이미지
FROM python:3.12-slim

# 런타임 의존성만 설치
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && useradd -m -u 1000 appuser

WORKDIR /app

# 빌드 단계에서 설치된 패키지 복사
COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# 애플리케이션 코드 복사
COPY --chown=appuser:appuser . .

USER appuser

EXPOSE 8000

ENTRYPOINT ["/app/entrypoint.sh"]
```

## 18. 최종 배포 체크리스트

### 18.1 배포 전 체크리스트

#### 개발 환경 체크리스트
- [ ] 모든 서비스 로컬 빌드 성공
- [ ] 환경 변수 파일 (.env.dev) 준비
- [ ] Docker 및 Docker Compose 설치 확인
- [ ] 네트워크 포트 충돌 확인
- [ ] 의존성 버전 호환성 확인

#### 운영 환경 체크리스트
- [ ] SSL 인증서 준비 및 설정
- [ ] 환경 변수 파일 (.env.prod) 보안 검토
- [ ] 데이터베이스 백업 전략 수립
- [ ] 모니터링 시스템 구축
- [ ] 로그 수집 시스템 구축
- [ ] 알림 시스템 설정
- [ ] 리소스 제한 설정
- [ ] 보안 강화 설정 적용

### 18.2 배포 후 체크리스트

#### 즉시 확인 사항
- [ ] 모든 컨테이너 정상 실행 확인
- [ ] 헬스체크 엔드포인트 응답 확인
- [ ] Frontend 페이지 로딩 확인
- [ ] Backend API 응답 확인
- [ ] 데이터베이스 연결 확인
- [ ] LLM 서비스 응답 확인

#### 장기 모니터링 설정
- [ ] 자동 백업 스케줄 설정
- [ ] 로그 로테이션 설정
- [ ] 성능 모니터링 대시보드 구성
- [ ] 알림 규칙 설정
- [ ] 장애 복구 절차 문서화
